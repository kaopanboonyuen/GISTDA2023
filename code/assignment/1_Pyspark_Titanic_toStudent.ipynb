{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ebuHEZiV2C_v"
      },
      "source": [
        "# 1_Pyspark_Titanic_toStudent\n",
        "\n",
        "![](https://github.com/kaopanboonyuen/GISTDA2023/raw/main/img/gistda_day2.png)\n",
        "\n",
        "We check if we are in Google Colab.  If this is the case, install all necessary packages.\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 3.2.1 with hadoop 3.2, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab.\n",
        "Learn more from [A Must-Read Guide on How to Work with PySpark on Google Colab for Data Scientists!](https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/)\n",
        "\n",
        "credit: Natawut Nupairoj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KujcS5YNUql9"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXOVcrD1UtOO"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "    !wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop2.tgz\n",
        "    !tar xf spark-3.3.2-bin-hadoop2.tgz\n",
        "    !mv spark-3.3.2-bin-hadoop2 spark\n",
        "    !pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPJ0vfHl2ITr"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  import os\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "  os.environ[\"SPARK_HOME\"] = \"/content/spark\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBhQADru2IKe"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5WsSSZQNUmlM"
      },
      "source": [
        "# Pyspark_DataFrame_Titanic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9nbye5SMoBM",
        "outputId": "349dcad4-bd83-4feb-82db-4ba9e7f8520a"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/kaopanboonyuen/Kao/raw/master/dataset/sparklab/titanic.csv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFSWxftEu2Y"
      },
      "source": [
        "#1 Prepare environment (SparkContext, SparkSession)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xev4WUGpUmlO"
      },
      "outputs": [],
      "source": [
        "#1 - import module\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
        "from pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTn4sebbUmlU"
      },
      "outputs": [],
      "source": [
        "#2 - Create spark context\n",
        "# Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "a9Bfje4oUmlW",
        "outputId": "d309b79a-3178-40e2-b89a-3ed1226f621f"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n",
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjiKZG_rUmle",
        "outputId": "eab5409a-6871-4290-ea62-ff3c5209bbd3"
      },
      "outputs": [],
      "source": [
        "sc._conf.getAll()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tERkcCnOUmlj",
        "outputId": "2456d54d-edf1-466d-b0c7-d2f8fe1dc578",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print (sc.getConf().toDebugString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb-VUw3xUmlm",
        "outputId": "ee35bdf8-8d75-4289-b592-3ddf078fbdd8"
      },
      "outputs": [],
      "source": [
        "#3 - Setup SparkSession(SparkSQL)\n",
        "#Fill code here\n",
        "from pyspark.sql import SparkSession\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Rjwln5FKo0"
      },
      "source": [
        "#2 read titanic.csv and printSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CTjQok7Umlr",
        "outputId": "822d32c4-ad14-47fc-b238-fd65f03829d9"
      },
      "outputs": [],
      "source": [
        "#4 - Read file to spark DataFrame\n",
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f6xzIJpuU7mS",
        "outputId": "ad1a2610-59a7-449f-f3ac-4abd6f0f2f0e"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "73kCTt_pFRB9"
      },
      "source": [
        "#3 sample 5% with seed = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9pnKv-SI_akT",
        "outputId": "2edaaf48-1b43-4dbd-9bc3-e93cb0f4764c"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DcPj8d2aFlmB"
      },
      "source": [
        "#4 rename Sex to Gender (to new varaible 'renamed_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2dkpiBR_anG",
        "outputId": "5ea67600-5e1b-4759-a3ef-420367c1b258"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XduO4pOPYhDG"
      },
      "outputs": [],
      "source": [
        "renamed_df = data_df.withColumnRenamed(\"Sex\",\"Gender\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gmbvqYdIGDjf"
      },
      "source": [
        "#5 create column initial (code given)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6he0XT5FWbW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4NSWv2E_a0t"
      },
      "outputs": [],
      "source": [
        "titanic_df = renamed_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRAc7nXB_aiz",
        "outputId": "478ff74e-37dd-44e9-cad4-f9425085a829"
      },
      "outputs": [],
      "source": [
        "titanic_df.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jFLCbEmFGSs0"
      },
      "source": [
        "#6 count by gender and count by survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4hb2uD4_aqn",
        "outputId": "003e2836-4484-4da8-89dc-1b0a664ebf58"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtoodmka_aua",
        "outputId": "090664e4-157d-4202-eab2-fac2f71db596"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0OzRtF3Bs7n",
        "outputId": "c47b58de-d1e0-4722-e2a8-43df4f7cea93"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHOiknZSBE_9"
      },
      "outputs": [],
      "source": [
        "#createOrReplaceTempView(\"titanic\")\n",
        "#Fill code here\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0sNCqsdEGn1N"
      },
      "source": [
        "#7 create view and use sql to compute average age and fare by survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUH761YP_ax3",
        "outputId": "3dee0ed5-60bb-4dd4-8ae8-ee68e7eff7b5"
      },
      "outputs": [],
      "source": [
        "#Fill code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V0zyvNEHSuP"
      },
      "outputs": [],
      "source": [
        "spark.catalog.dropTempView(\"titanic\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1_Pyspark_Titanic_toStudent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
