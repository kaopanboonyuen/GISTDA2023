{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_3C2-BbEQ67J"
      },
      "source": [
        "# A Simple Introduction to Web Scraping with Beautiful Soup\n",
        "\n",
        "![](https://github.com/kaopanboonyuen/GISTDA2023/raw/main/img/gistda_day1.png)\n",
        "\n",
        "\n",
        "Credit: \n",
        "\n",
        "[1] https://realpython.com/beautiful-soup-web-scraper-python/\n",
        "\n",
        "[2] https://www.analyticsvidhya.com/blog/2021/08/a-simple-introduction-to-web-scraping-with-beautiful-soup/\n",
        "\n",
        "[3] https://www.scrapingbee.com/blog/python-web-scraping-beautiful-soup/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4zllJG7LPYA2"
      },
      "source": [
        "# API Scraping using Twitter\n",
        "\n",
        "![](https://www.techbooky.com/wp-content/uploads/2021/11/twitter-api.jpeg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uKy8p4x69N82"
      },
      "source": [
        "# IMPORT LIBS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KvzgzH6KB2q",
        "outputId": "f8f04a3b-80a6-4e9b-9636-a4cc507e8973"
      },
      "outputs": [],
      "source": [
        "#!pip install snscrape\n",
        "!pip install --upgrade git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "!pip install -q pythainlp\n",
        "!pip install -q pythainlp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g-tVbznx9RK1"
      },
      "source": [
        "# DOWNLOAD THAI FONT FOR WORD CLOUD PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brdfM4FM78DO"
      },
      "outputs": [],
      "source": [
        "!wget -q http://www.arts.chula.ac.th/ling/wp-content/uploads/TH-Sarabun_Chula1.1.zip -O font.zip\n",
        "!unzip -qj font.zip TH-Sarabun_Chula1.1/THSarabunChula-Regular.ttf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtOgAiBdKCUm"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import pythainlp\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XdCPl50Zmmd"
      },
      "outputs": [],
      "source": [
        "def thai_tokenizer(sentence):\n",
        "    return word_tokenize(sentence, engine='newmm')\n",
        "\n",
        "def remove_url(text):\n",
        "    urlPattern = \"((https?|ftp|gopher|telnet|file|Unsure|http):((//)|(\\\\\\\\))+[\\\\w\\\\d:#@%/;$()~_?\\\\+-=\\\\\\\\\\\\.&]*)\"\n",
        "    text = re.sub(urlPattern, '', text)\n",
        "    return text\n",
        "\n",
        "def remove_rt(text):\n",
        "    text = re.sub('^rt @[\\\\w]*: ', '', text).strip()\n",
        "    return text\n",
        "\n",
        "def remove_at(text):\n",
        "    text = re.sub('@[\\\\w]*', '', text).strip()\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower().replace('\\n', '').replace('\\t', '')\n",
        "    text = remove_url(text)\n",
        "    text = remove_rt(text)\n",
        "    text = remove_at(text)\n",
        "    text = (text\n",
        "            .replace(':', ' ')\n",
        "            .replace(',', ' ')\n",
        "            .replace('!', ' ')\n",
        "            .replace('#', ' ')\n",
        "            .replace('(', ' ')\n",
        "            .replace(')', ' ')\n",
        "            .replace('\"', ' ')\n",
        "            .replace(\"'\", ' ')\n",
        "            .replace('?', ' ')\n",
        "            .replace('”', ' ')\n",
        "            .replace(\"’\", ' ')\n",
        "           )\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    text = re.sub('\\.+', '\\.', text)\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r92lOBgN9V7Q"
      },
      "source": [
        "# TWITTER SCRAPING USING SNTWITTER WITH YOUR KEYWORD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvNlTFUKIeM",
        "outputId": "304ee439-4481-433b-b500-52235eb36d74"
      },
      "outputs": [],
      "source": [
        "# Set up the search query\n",
        "search_term = \"ลุงตู่\"\n",
        "since_date = \"2022-01-01\"\n",
        "until_date = \"2023-01-31\"\n",
        "#geocode = \"13.736717,100.523186, 50km\" # search within 50 km of bangkok\n",
        "\n",
        "# Setting variables to be used below\n",
        "maxTweets = 500\n",
        "\n",
        "# Creating list to append tweet data to\n",
        "tweets_list = []\n",
        "\n",
        "# create the search query\n",
        "query = f\"{search_term} since:{since_date} until:{until_date}\"\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):    \n",
        "    if i > maxTweets:\n",
        "        break\n",
        "    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.username])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKLXEDEzN-bX"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe from the tweets list above\n",
        "df = pd.DataFrame(tweets_list, columns=['datetime', 'tweet id', 'text', 'username'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pLhomvASP52d",
        "outputId": "958eb3d2-3b74-43ca-c8c8-8bae9daaf16a"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wQ6A6G8JZnhy",
        "outputId": "800c338b-d28b-4e30-b21a-cc90e02a7ec9"
      },
      "outputs": [],
      "source": [
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "0GDOMpzrglCO",
        "outputId": "b71aa9cd-42f5-42ee-d85c-739448683495"
      },
      "outputs": [],
      "source": [
        "df[['text', 'clean_text']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSLyYvgeZz-9"
      },
      "outputs": [],
      "source": [
        "df['tokens'] = df['clean_text'].apply(word_tokenize)\n",
        "\n",
        "tokens = df.explode('tokens')\n",
        "word_count = tokens['tokens'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1A65p8d4ATW",
        "outputId": "fddf1b69-d6a0-4204-f4fb-6bf90cbd5081"
      },
      "outputs": [],
      "source": [
        "word_count.sort_values(ascending=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5fBID2i89men"
      },
      "source": [
        "# FLATTEN LIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdV4riPb6wSP"
      },
      "outputs": [],
      "source": [
        "flat_list = [item for sublist in df['tokens'].tolist()  for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IObPMAPt6wUh"
      },
      "outputs": [],
      "source": [
        "word = []\n",
        "for i in flat_list:\n",
        "  if ' ' not in i:\n",
        "    word.append(i)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cTv4RDgR9oMg"
      },
      "source": [
        "# WORD CLOUD PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "rU5heoNx4A8T",
        "outputId": "3f323fbb-b7f9-416f-a4bb-ed3eb63236c0"
      },
      "outputs": [],
      "source": [
        "# Create sample data\n",
        "data = {'text': word}\n",
        "\n",
        "# Convert data to pandas DataFrame\n",
        "df_wc = pd.DataFrame(data)\n",
        "\n",
        "# Get word frequencies using value_counts() method\n",
        "word_freq = df_wc['text'].value_counts()\n",
        "\n",
        "# Create word cloud object\n",
        "wordcloud = WordCloud(font_path='THSarabunChula-Regular.ttf',width=800, height=800, background_color='white', colormap='inferno').generate_from_frequencies(word_freq)\n",
        "\n",
        "# Display the generated wordcloud image\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
