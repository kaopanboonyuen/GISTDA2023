{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZYmUUGRuIg1"
      },
      "source": [
        "# Spark Preparation\n",
        "We check if we are in Google Colab.  If this is the case, install all necessary packages.\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 3.2.1 with hadoop 3.2, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab.\n",
        "Learn more from [A Must-Read Guide on How to Work with PySpark on Google Colab for Data Scientists!](https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ExYymIWJuIg_"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gezOG6MiuIhB"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "    !wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "    !tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "    !mv spark-3.2.1-bin-hadoop3.2 spark\n",
        "    !pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r7JUdnC7uIhC"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  import os\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "  os.environ[\"SPARK_HOME\"] = \"/content/spark\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OtyMyTOuIhD"
      },
      "source": [
        "# Start a Local Cluster\n",
        "Use findspark.init() to start a local cluster.  If you plan to use remote cluster, skip the findspark.init() and change the cluster_url according."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-wMS2LmVuIhE"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3HWQm8NYuIhE"
      },
      "outputs": [],
      "source": [
        "cluster_url = 'local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X1Umd4VauIhF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IW713i9wuIhG"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(cluster_url)\\\n",
        "        .appName('SparkSQL')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKX-Oo1VuIhH"
      },
      "source": [
        "# Spark SQL Data Preparation\n",
        "\n",
        "First, we read a csv file.  We can provide option such as delimiter and header.  We then rename the colume names to remove dot ('.') in the names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZjeU4JVduIhI",
        "outputId": "fa2a9ff5-cdf5-4403-a59f-2d7126faebf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-20 14:43:18--  https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/code/week9_spark/bank-additional-full.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kaopanboonyuen/2110446_DataScience_2021s2/main/code/week9_spark/bank-additional-full.csv [following]\n",
            "--2022-03-20 14:43:18--  https://raw.githubusercontent.com/kaopanboonyuen/2110446_DataScience_2021s2/main/code/week9_spark/bank-additional-full.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5834924 (5.6M) [text/plain]\n",
            "Saving to: ‘bank-additional-full.csv’\n",
            "\n",
            "bank-additional-ful 100%[===================>]   5.56M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-20 14:43:19 (154 MB/s) - ‘bank-additional-full.csv’ saved [5834924/5834924]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/kaopanboonyuen/2110446_DataScience_2021s2/raw/main/code/week9_spark/bank-additional-full.csv -O bank-additional-full.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OZICg5xDuIhI"
      },
      "outputs": [],
      "source": [
        "path = 'bank-additional-full.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nz59EECLuIhJ"
      },
      "outputs": [],
      "source": [
        "df = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l2KOjusluIhJ",
        "outputId": "d7ad6fc1-c463-41f0-c1a5-e2a5b6802758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'job',\n",
              " 'marital',\n",
              " 'education',\n",
              " 'default',\n",
              " 'housing',\n",
              " 'loan',\n",
              " 'contact',\n",
              " 'month',\n",
              " 'day_of_week',\n",
              " 'duration',\n",
              " 'campaign',\n",
              " 'pdays',\n",
              " 'previous',\n",
              " 'poutcome',\n",
              " 'emp.var.rate',\n",
              " 'cons.price.idx',\n",
              " 'cons.conf.idx',\n",
              " 'euribor3m',\n",
              " 'nr.employed',\n",
              " 'y']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m2XB0Dg6uIhK"
      },
      "outputs": [],
      "source": [
        "cols = [c.replace('.', '_') for c in df.columns]\n",
        "df = df.toDF(*cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e1GqVfxSuIhK",
        "outputId": "5bab7cb2-ecf3-4423-b571-63b2c25fef7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'job',\n",
              " 'marital',\n",
              " 'education',\n",
              " 'default',\n",
              " 'housing',\n",
              " 'loan',\n",
              " 'contact',\n",
              " 'month',\n",
              " 'day_of_week',\n",
              " 'duration',\n",
              " 'campaign',\n",
              " 'pdays',\n",
              " 'previous',\n",
              " 'poutcome',\n",
              " 'emp_var_rate',\n",
              " 'cons_price_idx',\n",
              " 'cons_conf_idx',\n",
              " 'euribor3m',\n",
              " 'nr_employed',\n",
              " 'y']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTzlvMoquIhL"
      },
      "source": [
        "Check out data and schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lRiJKu4euIhL",
        "outputId": "887b7577-d918-45a5-a989-12d90d633bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
            "|age|      job|marital|  education|default|housing|loan|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|emp_var_rate|cons_price_idx|cons_conf_idx|euribor3m|nr_employed|  y|\n",
            "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
            "| 56|housemaid|married|   basic.4y|     no|     no|  no|telephone|  may|        mon|     261|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|\n",
            "| 57| services|married|high.school|unknown|     no|  no|telephone|  may|        mon|     149|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|\n",
            "| 37| services|married|high.school|     no|    yes|  no|telephone|  may|        mon|     226|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|\n",
            "| 40|   admin.|married|   basic.6y|     no|     no|  no|telephone|  may|        mon|     151|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|\n",
            "| 56| services|married|high.school|     no|     no| yes|telephone|  may|        mon|     307|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|\n",
            "+---+---------+-------+-----------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": false,
        "id": "WQhMsyzwuIhL",
        "outputId": "09912591-37dc-4f80-dcb2-c5579981df12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: string (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- day_of_week: string (nullable = true)\n",
            " |-- duration: string (nullable = true)\n",
            " |-- campaign: string (nullable = true)\n",
            " |-- pdays: string (nullable = true)\n",
            " |-- previous: string (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- emp_var_rate: string (nullable = true)\n",
            " |-- cons_price_idx: string (nullable = true)\n",
            " |-- cons_conf_idx: string (nullable = true)\n",
            " |-- euribor3m: string (nullable = true)\n",
            " |-- nr_employed: string (nullable = true)\n",
            " |-- y: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hz1j9hyuIhM"
      },
      "source": [
        "Spark SQL seems to not perform any guess on datatype.  To convert to proper data type, we cast each column to proper type using **'cast'** and replace back to the same column using **'withColumn'**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2Oj3iIXuuIhM"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('age', df.age.cast('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5qXqo3QGuIhN"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N4tY780nuIhN"
      },
      "outputs": [],
      "source": [
        "cols = ['age', 'duration', 'campaign', 'pdays', 'previous', 'nr_employed']\n",
        "for c in cols:\n",
        "    df = df.withColumn(c, col(c).cast('int'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vxb5wKe4uIhO"
      },
      "outputs": [],
      "source": [
        "cols = ['emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m']\n",
        "for c in cols:\n",
        "    df = df.withColumn(c, col(c).cast('double'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwKe1YCXuIhP"
      },
      "source": [
        "Cast and also rename the column y to label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9KuStuONuIhP"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('label', df.y.cast('boolean'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": false,
        "id": "PW0kUHSAuIhP",
        "outputId": "85d3838b-99f4-4877-add4-2559bdfdd639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- day_of_week: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- emp_var_rate: double (nullable = true)\n",
            " |-- cons_price_idx: double (nullable = true)\n",
            " |-- cons_conf_idx: double (nullable = true)\n",
            " |-- euribor3m: double (nullable = true)\n",
            " |-- nr_employed: integer (nullable = true)\n",
            " |-- y: string (nullable = true)\n",
            " |-- label: boolean (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhaCsVP_uIhP"
      },
      "source": [
        "# Spark SQL Commands\n",
        "\n",
        "We can select some columns using **'select'** and select some rows using **'filter'**.  Note that we can perform basic math to columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "o4tT-7x1uIhQ",
        "outputId": "f2ebf358-2a84-4e63-8f9a-9ccd3b881600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-------+\n",
            "|      job|  education|housing|\n",
            "+---------+-----------+-------+\n",
            "|housemaid|   basic.4y|     no|\n",
            "| services|high.school|     no|\n",
            "| services|high.school|    yes|\n",
            "|   admin.|   basic.6y|     no|\n",
            "| services|high.school|     no|\n",
            "+---------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(df['job'], df['education'], df['housing']).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PLp6ISdcuIhQ",
        "outputId": "4971358a-861e-40a6-9749-f95749556df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+-----+---------+------------------+\n",
            "|age|duration|pdays|(age * 2)|(duration + pdays)|\n",
            "+---+--------+-----+---------+------------------+\n",
            "| 56|     261|  999|      112|              1260|\n",
            "| 57|     149|  999|      114|              1148|\n",
            "| 37|     226|  999|       74|              1225|\n",
            "| 40|     151|  999|       80|              1150|\n",
            "| 56|     307|  999|      112|              1306|\n",
            "| 45|     198|  999|       90|              1197|\n",
            "| 59|     139|  999|      118|              1138|\n",
            "| 41|     217|  999|       82|              1216|\n",
            "| 24|     380|  999|       48|              1379|\n",
            "| 25|      50|  999|       50|              1049|\n",
            "+---+--------+-----+---------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(df['age'], df['duration'], df['pdays'], df['age']*2, df['duration']+df['pdays']).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CkmrTgqauIhR",
        "outputId": "2f16cb11-7f57-48e5-b5aa-32dfabb3cc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-------+-----------------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+-----+\n",
            "|age|        job|marital|        education|default|housing|loan|  contact|month|day_of_week|duration|campaign|pdays|previous|   poutcome|emp_var_rate|cons_price_idx|cons_conf_idx|euribor3m|nr_employed|  y|label|\n",
            "+---+-----------+-------+-----------------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+-----+\n",
            "| 25|   services| single|      high.school|     no|    yes|  no|telephone|  may|        mon|      50|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|false|\n",
            "| 41|blue-collar|married|          unknown|unknown|     no|  no|telephone|  may|        mon|      55|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|false|\n",
            "| 30| unemployed|married|      high.school|     no|     no|  no|telephone|  may|        mon|      38|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|false|\n",
            "| 35| technician|married|university.degree|     no|     no| yes|telephone|  may|        mon|      99|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|false|\n",
            "| 59| technician|married|          unknown|     no|    yes|  no|telephone|  may|        mon|      93|       1|  999|       0|nonexistent|         1.1|        93.994|        -36.4|    4.857|       5191| no|false|\n",
            "+---+-----------+-------+-----------------+-------+-------+----+---------+-----+-----------+--------+--------+-----+--------+-----------+------------+--------------+-------------+---------+-----------+---+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df['duration'] < 100).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k8sIBlkKuIhR",
        "outputId": "2cd073a6-8e35-4fe9-e292-d5964c9c2187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "|age| marital|\n",
            "+---+--------+\n",
            "| 61| married|\n",
            "| 61| married|\n",
            "| 61| married|\n",
            "| 63|divorced|\n",
            "| 62| married|\n",
            "+---+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter((df['age'] > 60) & (df['age'] <= 65)).select('age', 'marital').show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRwiFe17uIhR"
      },
      "source": [
        "# Aggregate and Groupby Functions\n",
        "We can use several built-in aggegrate functions.  We can also use groupby for group operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cqjTgj-buIhS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import avg, min, max, countDistinct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "afPR_WrMuIhS",
        "outputId": "ec92dd04-fc4e-4d27-d570-2d53752947fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+-------------+\n",
            "|         avg(age)|min(age)|max(duration)|\n",
            "+-----------------+--------+-------------+\n",
            "|40.02406040594348|      17|         4918|\n",
            "+-----------------+--------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(avg('age'), min('age'), max('duration')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfxUqhI9uIhS"
      },
      "source": [
        "Groupby function allows us to work data in groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jAnGd3KduIhZ",
        "outputId": "e5aee29d-7796-47e2-9954-b2a694b6699f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "| marital|count|\n",
            "+--------+-----+\n",
            "| unknown|   80|\n",
            "|divorced| 4612|\n",
            "| married|24928|\n",
            "|  single|11568|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupby('marital').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LOnsxfl3uIhZ",
        "outputId": "3f6c8ba0-1138-497f-dbc5-a21aec2507d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+--------+\n",
            "| marital|          education|min(age)|\n",
            "+--------+-------------------+--------+\n",
            "|divorced|        high.school|      24|\n",
            "|divorced|            unknown|      26|\n",
            "| unknown|  university.degree|      25|\n",
            "| unknown|            unknown|      31|\n",
            "| married|professional.course|      22|\n",
            "|  single|           basic.9y|      17|\n",
            "| married|           basic.4y|      20|\n",
            "| married|  university.degree|      23|\n",
            "| unknown|           basic.9y|      30|\n",
            "|divorced|           basic.4y|      25|\n",
            "|divorced|           basic.9y|      24|\n",
            "|  single|professional.course|      20|\n",
            "| married|           basic.9y|      21|\n",
            "|divorced|           basic.6y|      26|\n",
            "| unknown|professional.course|      29|\n",
            "|  single|           basic.6y|      18|\n",
            "|  single|            unknown|      17|\n",
            "| married|        high.school|      21|\n",
            "| married|            unknown|      21|\n",
            "| unknown|        high.school|      27|\n",
            "+--------+-------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupby('marital', 'education').agg({'age': 'min'}).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuZQ3tI-uIhZ"
      },
      "source": [
        "# User-Defined Function\n",
        "We can create user-defined function using udf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "by7kXr7ruIhZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MvCWGL-_uIha"
      },
      "outputs": [],
      "source": [
        "def agegroup_mapping(age): \n",
        "    if age < 25:\n",
        "        return 'young'\n",
        "    if age < 55:\n",
        "        return 'adult'\n",
        "    return 'senior'\n",
        "\n",
        "to_agegroup = udf(agegroup_mapping, StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EWktrSiwuIha",
        "outputId": "c4800830-34b9-4107-c444-13ddad08cd59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------------+\n",
            "|age|agegroup_mapping(age)|\n",
            "+---+---------------------+\n",
            "| 56|               senior|\n",
            "| 57|               senior|\n",
            "| 37|                adult|\n",
            "| 40|                adult|\n",
            "| 56|               senior|\n",
            "+---+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select('age', to_agegroup('age')).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wP3fEpZtuIhb",
        "outputId": "d3d1d11f-e5d0-433e-ad06-3232e5bc7575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "|age|agegroup|\n",
            "+---+--------+\n",
            "| 56|  senior|\n",
            "| 57|  senior|\n",
            "| 37|   adult|\n",
            "| 40|   adult|\n",
            "| 56|  senior|\n",
            "| 45|   adult|\n",
            "| 59|  senior|\n",
            "| 41|   adult|\n",
            "| 24|   young|\n",
            "| 25|   adult|\n",
            "+---+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_df = df.withColumn('agegroup', to_agegroup(df.age))\n",
        "new_df.select(new_df['age'], new_df['agegroup']).show(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "2-SparkSQL.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}